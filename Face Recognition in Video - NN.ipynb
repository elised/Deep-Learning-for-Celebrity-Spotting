{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popular Figures Identification in Historic Movies via Neural-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Import of Libraries\n",
    "\n",
    "#Image Processing\n",
    "import scipy.sparse.linalg\n",
    "from PIL import Image as Image, ImageDraw as Imk\n",
    "from IPython.display import Image, display\n",
    "import scipy \n",
    "\n",
    "#Dilib Libraries and skImage\n",
    "import dlib as dlib\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from skimage.io import imread_collection\n",
    "import skimage as sk\n",
    "import skimage.io as io\n",
    "import os\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile,join\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "#Dealing with Files\n",
    "import cv2\n",
    "import glob\n",
    "from google_images_download import google_images_download \n",
    "import csv\n",
    "\n",
    "#Face Recognintion\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "\n",
    "#Math \n",
    "import math\n",
    "from sklearn import neighbors\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy.core.defchararray as np_f\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#TensorFlow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "epsilon = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to built a model for recognizing public figures Jean Paul Belmonod, Bridgitte Bardot, Elisabeth Reine Mere and Charles De Gaulle in historic films. A neural network is trained on a set of images and tested on videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Training Data From Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training Data was generated from Google Image data. The images were selected by size and quality. Large and frontal faces are suited best. For the purpose of increasing the accuracy, images were choosen in which the depicted people are about the same age as in the videos. In the following code, the face_recognition library encoding was applied to individual images. One encoding per celebrity is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract encoding from each image\n",
    "#This is a test, once it works, we can apply it to frames extracted from video \n",
    "img_dir = \"Train_ImagefromVideo\" #Enter Directory of all images \n",
    "data_path = os.path.join(img_dir,'*jpg')\n",
    "files = glob.glob(data_path)\n",
    "loaded_image = []\n",
    "encodings = []\n",
    "labels = []\n",
    "i = 0\n",
    "for filepath in files:\n",
    "    img = face_recognition.load_image_file(filepath)\n",
    "    ims = img[:, :, ::-1]\n",
    "    loaded_image = np.asarray(ims)\n",
    "    enco = face_recognition.face_encodings(loaded_image)\n",
    "    ## Checking if there is only one encoding, if there is more/less, then the image will not be included in the testing\n",
    "    if len(enco) == 1:\n",
    "        ## todo: either keep this indexing method or keep separate running tally (so as not to have missing vals)\n",
    "        labels.append(filepath.split(\"/\")[1].split(\"_\")[0])\n",
    "        encodings.append(enco[0])\n",
    "\n",
    "encodings = np.asarray(encodings)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the encodings, the arrays are stacked and brought into the right shape. Each image encoding consists our of 128 features. Therefore the shape of the data is (n, p), where n is the number of images and p is the number of features. In order to facilitate the anlysys of the data and the extraction of a CSV File, the data array generated is converted to a CSV file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array depicted above into a pandas df to facility export as csv\n",
    "Celebrity_Face_Encoding = pd.DataFrame(encodings)\n",
    "\n",
    "# Create labels dataframe\n",
    "labelsDF = pd.DataFrame(labels)\n",
    "labels_onehot = pd.get_dummies(labelsDF)\n",
    "y_train = labels_onehot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024127</td>\n",
       "      <td>0.085475</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>-0.131138</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>-0.014221</td>\n",
       "      <td>-0.107343</td>\n",
       "      <td>0.041117</td>\n",
       "      <td>-0.110221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068879</td>\n",
       "      <td>0.020501</td>\n",
       "      <td>-0.026679</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>-0.131504</td>\n",
       "      <td>-0.166882</td>\n",
       "      <td>-0.096925</td>\n",
       "      <td>-0.127127</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>0.025766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.057144</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.126350</td>\n",
       "      <td>-0.026666</td>\n",
       "      <td>-0.109886</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>0.022626</td>\n",
       "      <td>-0.121540</td>\n",
       "      <td>0.188620</td>\n",
       "      <td>-0.085064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>-0.019939</td>\n",
       "      <td>-0.112282</td>\n",
       "      <td>-0.055040</td>\n",
       "      <td>-0.141482</td>\n",
       "      <td>0.047746</td>\n",
       "      <td>-0.010327</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>0.072041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.047625</td>\n",
       "      <td>0.075023</td>\n",
       "      <td>0.056803</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>-0.146133</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>-0.054715</td>\n",
       "      <td>-0.195797</td>\n",
       "      <td>0.097233</td>\n",
       "      <td>-0.120349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059238</td>\n",
       "      <td>0.067262</td>\n",
       "      <td>-0.068762</td>\n",
       "      <td>-0.009893</td>\n",
       "      <td>-0.059077</td>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.055399</td>\n",
       "      <td>-0.111467</td>\n",
       "      <td>0.100648</td>\n",
       "      <td>0.043378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.112403</td>\n",
       "      <td>0.122914</td>\n",
       "      <td>0.057335</td>\n",
       "      <td>0.035374</td>\n",
       "      <td>-0.072395</td>\n",
       "      <td>-0.039396</td>\n",
       "      <td>-0.029620</td>\n",
       "      <td>-0.147109</td>\n",
       "      <td>0.160966</td>\n",
       "      <td>-0.017160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061651</td>\n",
       "      <td>0.058171</td>\n",
       "      <td>0.041382</td>\n",
       "      <td>0.129432</td>\n",
       "      <td>-0.113444</td>\n",
       "      <td>-0.163540</td>\n",
       "      <td>-0.026752</td>\n",
       "      <td>-0.059040</td>\n",
       "      <td>-0.061267</td>\n",
       "      <td>0.051140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013125</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>-0.067221</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>-0.016641</td>\n",
       "      <td>-0.077355</td>\n",
       "      <td>0.109896</td>\n",
       "      <td>-0.100729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>0.079056</td>\n",
       "      <td>-0.005817</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>-0.178581</td>\n",
       "      <td>-0.150615</td>\n",
       "      <td>-0.056889</td>\n",
       "      <td>-0.044019</td>\n",
       "      <td>0.036203</td>\n",
       "      <td>0.043336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.082264</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>0.035755</td>\n",
       "      <td>-0.008192</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>-0.031883</td>\n",
       "      <td>-0.149291</td>\n",
       "      <td>0.085397</td>\n",
       "      <td>-0.116676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>0.115006</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>0.030152</td>\n",
       "      <td>-0.184271</td>\n",
       "      <td>-0.192568</td>\n",
       "      <td>-0.047035</td>\n",
       "      <td>-0.016045</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.111671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.033157</td>\n",
       "      <td>-0.008132</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>-0.050992</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>-0.032090</td>\n",
       "      <td>-0.089819</td>\n",
       "      <td>0.075177</td>\n",
       "      <td>-0.082718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049820</td>\n",
       "      <td>0.062390</td>\n",
       "      <td>-0.013631</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>-0.188123</td>\n",
       "      <td>-0.177836</td>\n",
       "      <td>-0.057881</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.040356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.163669</td>\n",
       "      <td>0.058064</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.036525</td>\n",
       "      <td>-0.126451</td>\n",
       "      <td>0.033183</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>-0.179700</td>\n",
       "      <td>0.114085</td>\n",
       "      <td>-0.111724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064204</td>\n",
       "      <td>0.169654</td>\n",
       "      <td>-0.013303</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>-0.130710</td>\n",
       "      <td>-0.114165</td>\n",
       "      <td>0.052537</td>\n",
       "      <td>-0.080669</td>\n",
       "      <td>0.045099</td>\n",
       "      <td>0.068817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.111632</td>\n",
       "      <td>0.027450</td>\n",
       "      <td>0.082345</td>\n",
       "      <td>-0.026996</td>\n",
       "      <td>-0.118008</td>\n",
       "      <td>0.039777</td>\n",
       "      <td>-0.004962</td>\n",
       "      <td>-0.171604</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>-0.097224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.136349</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>-0.109773</td>\n",
       "      <td>-0.101723</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>-0.061758</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.149899</td>\n",
       "      <td>0.116029</td>\n",
       "      <td>0.037701</td>\n",
       "      <td>-0.041780</td>\n",
       "      <td>-0.089034</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.014557</td>\n",
       "      <td>-0.145252</td>\n",
       "      <td>0.151758</td>\n",
       "      <td>-0.134705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060797</td>\n",
       "      <td>0.026797</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.093102</td>\n",
       "      <td>-0.190019</td>\n",
       "      <td>-0.154799</td>\n",
       "      <td>0.035351</td>\n",
       "      <td>-0.072074</td>\n",
       "      <td>0.023827</td>\n",
       "      <td>0.100968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.024127  0.085475  0.017361  0.022435 -0.131138  0.042254 -0.014221   \n",
       "1 -0.057144  0.026751  0.126350 -0.026666 -0.109886 -0.011346  0.022626   \n",
       "2 -0.047625  0.075023  0.056803 -0.001579 -0.146133  0.013198 -0.054715   \n",
       "3 -0.112403  0.122914  0.057335  0.035374 -0.072395 -0.039396 -0.029620   \n",
       "4 -0.013125  0.004420  0.018207  0.023401 -0.067221  0.007791 -0.016641   \n",
       "5 -0.082264 -0.001531  0.035755 -0.008192 -0.027778  0.003319 -0.031883   \n",
       "6 -0.033157 -0.008132  0.018028  0.013672 -0.050992 -0.003994 -0.032090   \n",
       "7 -0.163669  0.058064  0.046579  0.036525 -0.126451  0.033183  0.003657   \n",
       "8 -0.111632  0.027450  0.082345 -0.026996 -0.118008  0.039777 -0.004962   \n",
       "9 -0.149899  0.116029  0.037701 -0.041780 -0.089034  0.014660  0.014557   \n",
       "\n",
       "        7         8         9      ...          118       119       120  \\\n",
       "0 -0.107343  0.041117 -0.110221    ...     0.068879  0.020501 -0.026679   \n",
       "1 -0.121540  0.188620 -0.085064    ...    -0.003703  0.063036 -0.019939   \n",
       "2 -0.195797  0.097233 -0.120349    ...     0.059238  0.067262 -0.068762   \n",
       "3 -0.147109  0.160966 -0.017160    ...     0.061651  0.058171  0.041382   \n",
       "4 -0.077355  0.109896 -0.100729    ...     0.057111  0.079056 -0.005817   \n",
       "5 -0.149291  0.085397 -0.116676    ...     0.043613  0.115006 -0.000633   \n",
       "6 -0.089819  0.075177 -0.082718    ...     0.049820  0.062390 -0.013631   \n",
       "7 -0.179700  0.114085 -0.111724    ...     0.064204  0.169654 -0.013303   \n",
       "8 -0.171604  0.208198 -0.097224    ...     0.018261  0.136349 -0.000828   \n",
       "9 -0.145252  0.151758 -0.134705    ...     0.060797  0.026797  0.029355   \n",
       "\n",
       "        121       122       123       124       125       126       127  \n",
       "0 -0.007188 -0.131504 -0.166882 -0.096925 -0.127127  0.066999  0.025766  \n",
       "1 -0.112282 -0.055040 -0.141482  0.047746 -0.010327  0.019579  0.072041  \n",
       "2 -0.009893 -0.059077 -0.137586 -0.055399 -0.111467  0.100648  0.043378  \n",
       "3  0.129432 -0.113444 -0.163540 -0.026752 -0.059040 -0.061267  0.051140  \n",
       "4  0.026445 -0.178581 -0.150615 -0.056889 -0.044019  0.036203  0.043336  \n",
       "5  0.030152 -0.184271 -0.192568 -0.047035 -0.016045  0.013198  0.111671  \n",
       "6  0.049777 -0.188123 -0.177836 -0.057881 -0.019701  0.009197  0.040356  \n",
       "7  0.005778 -0.130710 -0.114165  0.052537 -0.080669  0.045099  0.068817  \n",
       "8  0.018019 -0.109773 -0.101723  0.013157 -0.061758  0.043738  0.046051  \n",
       "9  0.093102 -0.190019 -0.154799  0.035351 -0.072074  0.023827  0.100968  \n",
       "\n",
       "[10 rows x 128 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first ten values to confirm results\n",
    "Celebrity_Face_Encoding.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export celebrity face encodings as a CSV File -> comment out so it does not create a new file each time its run\n",
    "'''\n",
    "Celebrity_Face_Encoding.to_csv(\"CSV_Files/X_train.csv\")\n",
    "labels_onehot.to_csv(\"CSV_Files/y_train.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final training data set is created here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purposes of easier reading\n",
    "\n",
    "X_train = encodings\n",
    "# y_train already defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting images to correct coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists, images will be written in same folder\n",
      "frame11920.jpg is not converted\n"
     ]
    }
   ],
   "source": [
    "# In case some images aren't converted to the right coloring\n",
    "# I used this when debugging for the encoding -> it may not be necessary\n",
    "# If not necessary do not run as it creates overhead\n",
    "\n",
    "# Note: Turns out not to be necessary\n",
    "\n",
    "path = r'Video7_Frames' # Source Folder\n",
    "dstpath = r'RGBConverted' # Destination Folder\n",
    "\n",
    "try:\n",
    "    #check if the specified already exists\n",
    "    makedirs(dstpath)\n",
    "except:\n",
    "    #if it does exist write images to the same fodler\n",
    "    print (\"Directory already exists, images will be written in same folder\")\n",
    "\n",
    "# Folder won't use\n",
    "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
    "\n",
    "for image in files:\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join(path,image))\n",
    "        #convert to right color\n",
    "        rgb_frame = img[:, :, ::-1]\n",
    "        #place image to path\n",
    "        dstPath = join(dstpath,image)\n",
    "        #write change colored frames to the new specified directory\n",
    "        cv2.imwrite(dstPath,rgb_frame)\n",
    "    except:\n",
    "        #exception in case the conversion was not succesful\n",
    "        print (\"{} is not converted\".format(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract encoding from each image\n",
    "\n",
    "img_dir = \"Test_Images\" #Enter Directory of all images \n",
    "data_path = os.path.join(img_dir,'*jpg')\n",
    "files = glob.glob(data_path)\n",
    "loaded_image = []\n",
    "encodings = []\n",
    "labels = []\n",
    "i = 0\n",
    "for filepath in files:\n",
    "    img = face_recognition.load_image_file(filepath)\n",
    "    ims = img[:, :, ::-1]\n",
    "    loaded_image = np.asarray(ims)\n",
    "    enco = face_recognition.face_encodings(loaded_image)\n",
    "    '''\n",
    "    for i in enco:\n",
    "        print(\"enco length:\", len(enco))\n",
    "        print(i)\n",
    "    '''\n",
    "    ## Checking if there is only one encoding, if there is more/less, then the image will not be included in the testing\n",
    "    if len(enco) == 1:\n",
    "        labels.append(filepath)\n",
    "        encodings.append(enco)\n",
    "\n",
    "encodings = np.asarray(encodings)\n",
    "labels = np.asarray(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np_f.replace(labels, 'Test_Images/', '')\n",
    "filepath_labels_fixed=[i.split('_')[0] for i in t] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings.resize(encodings.shape[0], 128)\n",
    "X_test = encodings\n",
    "X_test_DF = pd.DataFrame(encodings)\n",
    "y_test_DF = pd.DataFrame(filepath_labels_fixed)\n",
    "y_test_DF_onehot = pd.get_dummies(y_test_DF)\n",
    "y_test = y_test_DF_onehot.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will manually select images and label them in order to create our test data set. This is done as the labeling is even challenging for us as humans. Furthermore, we will remove any images that do not contain the right number of faces.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export celebrity face encodings as a CSV File -> comment out so it does not create a new file each time its run\n",
    "'''\n",
    "X_test_DF.to_csv(\"CSV_Files/X_test.csv\")\n",
    "y_test_DF_onehot.to_csv(\"CSV_Files/y_test.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skeleton for training neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = pd.DataFrame.from_csv(\"CSV_Files/Celebrity_Face_Encoding_nolabel.csv\")\\ny_train = pd.DataFrame.from_csv(\"CSV_Files/Labels_face_encoding.csv\")\\n\\nX_test = pd.DataFrame.from_csv(\"CSV_Files/Celebrity_Face_Encoding_nolabel_test.csv\")\\ny_test = pd.DataFrame.from_csv(\"CSV_Files/Labels_face_encoding_test.csv\")'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_train = pd.DataFrame.from_csv(\"CSV_Files/Celebrity_Face_Encoding_nolabel.csv\")\n",
    "y_train = pd.DataFrame.from_csv(\"CSV_Files/Labels_face_encoding.csv\")\n",
    "\n",
    "X_test = pd.DataFrame.from_csv(\"CSV_Files/Celebrity_Face_Encoding_nolabel_test.csv\")\n",
    "y_test = pd.DataFrame.from_csv(\"CSV_Files/Labels_face_encoding_test.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/faceNN.ckpt\"\n",
    "def facialNN(X_train, y_train, X_test, y_test, learning_rate = 0.1, training_epochs = 100, batch_size = 128, display_step = 1):\n",
    "    # Parameters\n",
    "\n",
    "    # tf Graph Input:  face encoding of length 128\n",
    "    x = tf.placeholder(tf.float32, [None, 128], name='InputData')\n",
    "    # how many people we're looking to classify:\n",
    "    # 4 historical figures\n",
    "    y = tf.placeholder(tf.float32, [None, 4], name='LabelData')\n",
    "\n",
    "    # Set model weights\n",
    "    # Note: no hidden layers here\n",
    "    W = tf.Variable(tf.zeros([128, 4]), name='Weights')\n",
    "    b = tf.Variable(tf.zeros([4]), name='Bias')\n",
    "\n",
    "    # Construct model and encapsulating all ops into scopes, making Tensorboard's Graph visualization more convenient\n",
    "    with tf.name_scope('Model'):\n",
    "        # Model\n",
    "        pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "    with tf.name_scope('Loss'):\n",
    "        # Minimize error using cross entropy\n",
    "        # We use tf.clip_by_value to avoid having too low numbers in the log function\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(tf.clip_by_value(pred, epsilon, 1.0)), reduction_indices=1))\n",
    "    with tf.name_scope('Adam'):\n",
    "        # Gradient Descent\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        # Accuracy\n",
    "        acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(\"Loss\", cost)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    tf.summary.scalar(\"Accuracy\", acc)\n",
    "    # Save results at a checkpoint (model_path)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #STEP 2 \n",
    "\n",
    "    # Launch the graph for training\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost = 0.\n",
    "            \n",
    "            # Run optimization op (backprop), cost op (to get loss value) and summary nodes\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: X_train, y: y_train})\n",
    "            \n",
    "            # Display logs per epoch step\n",
    "            if (epoch+1) % display_step == 0:\n",
    "                print(\"Epoch: \", '%02d' % (epoch+1), \"  =====> Loss=\", \"{:.9f}\".format(c))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Test model\n",
    "        # Calculate accuracy\n",
    "        accRate = acc.eval({x: X_test, y: y_test})\n",
    "        \n",
    "        print(\"Accuracy rate:\", accRate)\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        \n",
    "        '''# To test unknown faces\n",
    "        prediction=tf.argmax(y,1)\n",
    "        predList = prediction.eval(feed_dict={y: y_test})\n",
    "        '''\n",
    "        #print (predList)\n",
    "        return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  01   =====> Loss= 1.386294365\n",
      "Epoch:  02   =====> Loss= 1.249869347\n",
      "Epoch:  03   =====> Loss= 0.975380540\n",
      "Epoch:  04   =====> Loss= 0.766343415\n",
      "Epoch:  05   =====> Loss= 0.675655723\n",
      "Epoch:  06   =====> Loss= 0.561120033\n",
      "Epoch:  07   =====> Loss= 0.450502574\n",
      "Epoch:  08   =====> Loss= 0.380107999\n",
      "Epoch:  09   =====> Loss= 0.330492914\n",
      "Epoch:  10   =====> Loss= 0.283273935\n",
      "Epoch:  11   =====> Loss= 0.238732189\n",
      "Epoch:  12   =====> Loss= 0.203358799\n",
      "Epoch:  13   =====> Loss= 0.178692415\n",
      "Epoch:  14   =====> Loss= 0.159978658\n",
      "Epoch:  15   =====> Loss= 0.142220587\n",
      "Epoch:  16   =====> Loss= 0.124285191\n",
      "Epoch:  17   =====> Loss= 0.107715257\n",
      "Epoch:  18   =====> Loss= 0.094033822\n",
      "Epoch:  19   =====> Loss= 0.083542123\n",
      "Epoch:  20   =====> Loss= 0.075547650\n",
      "Epoch:  21   =====> Loss= 0.069027178\n",
      "Epoch:  22   =====> Loss= 0.063149333\n",
      "Epoch:  23   =====> Loss= 0.057505317\n",
      "Epoch:  24   =====> Loss= 0.052076556\n",
      "Epoch:  25   =====> Loss= 0.047051929\n",
      "Epoch:  26   =====> Loss= 0.042632364\n",
      "Epoch:  27   =====> Loss= 0.038915619\n",
      "Epoch:  28   =====> Loss= 0.035875998\n",
      "Epoch:  29   =====> Loss= 0.033400856\n",
      "Epoch:  30   =====> Loss= 0.031343557\n",
      "Epoch:  31   =====> Loss= 0.029566705\n",
      "Epoch:  32   =====> Loss= 0.027967677\n",
      "Epoch:  33   =====> Loss= 0.026486076\n",
      "Epoch:  34   =====> Loss= 0.025097962\n",
      "Epoch:  35   =====> Loss= 0.023802521\n",
      "Epoch:  36   =====> Loss= 0.022608355\n",
      "Epoch:  37   =====> Loss= 0.021522807\n",
      "Epoch:  38   =====> Loss= 0.020546656\n",
      "Epoch:  39   =====> Loss= 0.019673243\n",
      "Epoch:  40   =====> Loss= 0.018890299\n",
      "Epoch:  41   =====> Loss= 0.018183328\n",
      "Epoch:  42   =====> Loss= 0.017538138\n",
      "Epoch:  43   =====> Loss= 0.016943183\n",
      "Epoch:  44   =====> Loss= 0.016390232\n",
      "Epoch:  45   =====> Loss= 0.015874285\n",
      "Epoch:  46   =====> Loss= 0.015392775\n",
      "Epoch:  47   =====> Loss= 0.014944486\n",
      "Epoch:  48   =====> Loss= 0.014528591\n",
      "Epoch:  49   =====> Loss= 0.014143748\n",
      "Epoch:  50   =====> Loss= 0.013787904\n",
      "Epoch:  51   =====> Loss= 0.013458183\n",
      "Epoch:  52   =====> Loss= 0.013151267\n",
      "Epoch:  53   =====> Loss= 0.012863487\n",
      "Epoch:  54   =====> Loss= 0.012591636\n",
      "Epoch:  55   =====> Loss= 0.012332901\n",
      "Epoch:  56   =====> Loss= 0.012085248\n",
      "Epoch:  57   =====> Loss= 0.011847364\n",
      "Epoch:  58   =====> Loss= 0.011618629\n",
      "Epoch:  59   =====> Loss= 0.011398790\n",
      "Epoch:  60   =====> Loss= 0.011187959\n",
      "Epoch:  61   =====> Loss= 0.010986200\n",
      "Epoch:  62   =====> Loss= 0.010793554\n",
      "Epoch:  63   =====> Loss= 0.010609848\n",
      "Epoch:  64   =====> Loss= 0.010434708\n",
      "Epoch:  65   =====> Loss= 0.010267530\n",
      "Epoch:  66   =====> Loss= 0.010107586\n",
      "Epoch:  67   =====> Loss= 0.009954114\n",
      "Epoch:  68   =====> Loss= 0.009806348\n",
      "Epoch:  69   =====> Loss= 0.009663578\n",
      "Epoch:  70   =====> Loss= 0.009525269\n",
      "Epoch:  71   =====> Loss= 0.009390960\n",
      "Epoch:  72   =====> Loss= 0.009260355\n",
      "Epoch:  73   =====> Loss= 0.009133256\n",
      "Epoch:  74   =====> Loss= 0.009009586\n",
      "Epoch:  75   =====> Loss= 0.008889242\n",
      "Epoch:  76   =====> Loss= 0.008772191\n",
      "Epoch:  77   =====> Loss= 0.008658391\n",
      "Epoch:  78   =====> Loss= 0.008547728\n",
      "Epoch:  79   =====> Loss= 0.008440130\n",
      "Epoch:  80   =====> Loss= 0.008335425\n",
      "Epoch:  81   =====> Loss= 0.008233477\n",
      "Epoch:  82   =====> Loss= 0.008134163\n",
      "Epoch:  83   =====> Loss= 0.008037189\n",
      "Epoch:  84   =====> Loss= 0.007942522\n",
      "Epoch:  85   =====> Loss= 0.007849941\n",
      "Epoch:  86   =====> Loss= 0.007759340\n",
      "Epoch:  87   =====> Loss= 0.007670643\n",
      "Epoch:  88   =====> Loss= 0.007583740\n",
      "Epoch:  89   =====> Loss= 0.007498573\n",
      "Epoch:  90   =====> Loss= 0.007415057\n",
      "Epoch:  91   =====> Loss= 0.007333207\n",
      "Epoch:  92   =====> Loss= 0.007252957\n",
      "Epoch:  93   =====> Loss= 0.007174278\n",
      "Epoch:  94   =====> Loss= 0.007097081\n",
      "Epoch:  95   =====> Loss= 0.007021394\n",
      "Epoch:  96   =====> Loss= 0.006947116\n",
      "Epoch:  97   =====> Loss= 0.006874248\n",
      "Epoch:  98   =====> Loss= 0.006802703\n",
      "Epoch:  99   =====> Loss= 0.006732436\n",
      "Epoch:  100   =====> Loss= 0.006663426\n",
      "Optimization Finished!\n",
      "Accuracy rate: 0.90196085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/faceNN.ckpt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facialNN(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImageFiles(img_dir):\n",
    "    #Extract encoding from each image\n",
    "    #This is a test, once it works, we can apply it to frames extracted from video \n",
    "    data_path = os.path.join(img_dir,'*.jpg')\n",
    "    files = glob.glob(data_path)\n",
    "    loaded_image = []\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for filepath in files:\n",
    "        img = face_recognition.load_image_file(filepath)\n",
    "        ims = img[:, :, ::-1]\n",
    "        loaded_image = np.asarray(ims)\n",
    "        enco = face_recognition.face_encodings(loaded_image)\n",
    "\n",
    "        ## Checking if there is only one encoding, if there is more/less, then the image will not be included in the testing\n",
    "        if len(enco) == 1:\n",
    "            ## todo: either keep this indexing method or keep separate running tally (so as not to have missing vals)\n",
    "            labels.append(filepath)\n",
    "            encodings.append(enco)\n",
    "\n",
    "    encodings = np.asarray(encodings)\n",
    "    labels = np.asarray(labels)\n",
    "    return encodings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVideo(filename, model):\n",
    "    # Open the input movie file\n",
    "    input_movie = cv2.VideoCapture(filename)\n",
    "    #input_movie = cv2.VideoCapture(\"MGAFE0410353.01.mp4\")\n",
    "    length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    y = int(input_movie.get(3))\n",
    "    #print(\"Y\",y)\n",
    "    x = int(input_movie.get(4))\n",
    "    #print(\"X\",x)\n",
    "\n",
    "    # Create an output movie file (make sure resolution/frame rate matches input video!)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    cleanFilename = filename[:-4]\n",
    "    #cleanFilename = filename + \"_output.avi\"\n",
    "    cleanFilename = model + \"_\" + filename.split('/')[1] + \"_output.avi\"\n",
    "    output_movie = cv2.VideoWriter(cleanFilename, fourcc = fourcc, fps=24.0, frameSize=(y, x))\n",
    "    # Load some sample pictures and learn how to recognize them.\n",
    "    #Deep Learning Library face_encoding called\n",
    "    \n",
    "    return length, input_movie, output_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnToVideo(filename):\n",
    "    \n",
    "    length, input_movie, output_movie = readVideo(filename, \"nn\")\n",
    "    \n",
    "    known_faces, labels = readImageFiles(\"Train_ImagefromVideo\")\n",
    "    \n",
    "    # Initialize some variables\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    frame_number = 0\n",
    "    saver = tf.train.Saver()\n",
    "    x = tf.placeholder(tf.float32, [None, 128], name='InputData')\n",
    "    y = tf.placeholder(tf.float32, [None, 4], name='LabelData')\n",
    "\n",
    "    \n",
    "    #while input_movie.isOpened():\n",
    "    while True: \n",
    "        # Grab a single frame of video\n",
    "        ret, frame = input_movie.read()\n",
    "        #print(frame.shape)\n",
    "        frame_number += 1\n",
    "\n",
    "        # Quit when the input video file ends\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            print(\"Found a face\")\n",
    "            # See if the face is a match for the known face(s)\n",
    "            \n",
    "            # could make this logic a lot prettier\n",
    "            name = None\n",
    "            with tf.Session() as sess:\n",
    "                saver.restore(sess, model_path)\n",
    "                prediction=tf.argmax(y,1)\n",
    "                predList = prediction.eval(feed_dict={y: face_encoding})\n",
    "                #print(\"Accuracy:\", acc.eval({x: test_xs, m: test_ms, y: test_ys}))\n",
    "            #predList = facialNN(X_train, y_train, X_test, y_test)\n",
    "                                \n",
    "            if predList[0] == 0:\n",
    "                name = \"BrigitteBardot\"\n",
    "            elif predList[0] == 1:\n",
    "                name = \"CharlesDeGaulle\"\n",
    "            elif predList[0] == 2:\n",
    "                name = \"ElizabethReineMere\"\n",
    "            elif predList[0] == 3:\n",
    "                name = \"JeanPaulBelmondo\"\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "        # Label the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            if not name:\n",
    "                continue\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Write the resulting image to the output video file\n",
    "        print(\"Writing frame {} / {}\".format(frame_number, length))\n",
    "\n",
    "        # confirmed: frames are being read fine, the issue is writing each frame\n",
    "        output_movie.write(frame)\n",
    "\n",
    "    print(\"All done\")\n",
    "    # All done!\n",
    "    input_movie.release()\n",
    "    output_movie.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables to save",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-67d37cb2f674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnnToVideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test_Videos/MGAFE0008218--AS.01.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-9c9c9480bcfc>\u001b[0m in \u001b[0;36mnnToVideo\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mface_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mframe_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'InputData'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LabelData'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m       self.saver_def = self._builder.build(\n",
      "\u001b[0;31mValueError\u001b[0m: No variables to save"
     ]
    }
   ],
   "source": [
    "nnToVideo(\"Test_Videos/MGAFE0008218--AS.01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
